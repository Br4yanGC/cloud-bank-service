# MS5 - Analytics y Data Lake# MS5 - DataLake con AWS S3, Glue y Athena (ACTUALIZADO PARA EC2)



## 📋 DescripciónArquitectura completa de DataLake desplegada en **EC2 Ubuntu 22.04** con ingesta de datos desde múltiples fuentes, catalogación con Glue y consultas analíticas vía API REST.



Microservicio de analytics que consulta datos del Data Lake en AWS S3 usando AWS Athena. Proporciona dashboards ejecutivos, reportes de cuentas, análisis de transacciones y métricas de clientes a partir de datos históricos almacenados en formato Parquet.## 🏗️ Arquitectura



## 🎯 Propósito```

┌─────────────────────────────────────────────────────────────┐

- Proporcionar analytics y KPIs para ejecutivos del banco│                      EC2 Ubuntu 22.04                       │

- Consultar grandes volúmenes de datos históricos eficientemente│  ┌──────────────────────────────────────────────────────┐   │

- Generar reportes agregados desde el Data Lake│  │  Docker Containers (7 servicios)                     │   │

- Servir dashboards con métricas de negocio│  │  ├─ MySQL 8.0         (puerto 3307)                  │   │

│  │  ├─ PostgreSQL 15     (puerto 5433)                  │   │

## 🏗️ Arquitectura│  │  ├─ MongoDB 7.0       (puerto 27018)                 │   │

│  │  ├─ Ingester MySQL    (ingesta01-mysql)              │   │

```mermaid│  │  ├─ Ingester PostgreSQL (ingesta02-postgresql)       │   │

graph TB│  │  ├─ Ingester MongoDB  (ingesta03-mongodb)            │   │

    subgraph "MS5 - Analytics"│  │  └─ API REST FastAPI  (puerto 8000)                  │   │

        API[FastAPI Application]│  └──────────────────────────────────────────────────────┘   │

        AC[Athena Client]│                           │                                  │

        └───────────────────────────┼──────────────────────────────────┘

        API --> AC                            │

    end                            ↓ boto3 (JSON Lines)

            ┌──────────────────────────────────────┐

    Client[Dashboard/BI Tool] -->|HTTP REST| API        │         Amazon S3 (3 Buckets)        │

            │  ├─ raw-ms1-data-bgc (MySQL)         │

    AC -->|SQL Queries| Athena[AWS Athena]        │  ├─ raw-ms2-data-bgc (PostgreSQL)    │

    Athena -->|Query Results| AC        │  └─ raw-ms3-data-bgc (MongoDB)       │

            └──────────────┬───────────────────────┘

    Athena -->|Scans Data| S3[(AWS S3 Data Lake)]                       │

                           ↓ AWS Glue Crawlers

    subgraph "Data Lake Structure"        ┌──────────────────────────────────────┐

        S3 --> Clientes[/clientes/*.parquet/]        │   AWS Glue Data Catalog (9 tablas)   │

        S3 --> Cuentas[/cuentas/*.parquet/]        └──────────────┬───────────────────────┘

        S3 --> Transacciones[/transacciones/*.parquet/]                       │

    end                       ↓ Athena SQL Queries

            ┌──────────────────────────────────────┐

    DI[Data Ingester] -->|ETL Process| S3        │      Amazon Athena (Query Engine)    │

            └──────────────┬───────────────────────┘

    style API fill:#3498db,color:#fff                       │

    style Athena fill:#ff9900,color:#fff                       ↓ API REST (15+ endpoints)

    style S3 fill:#ff9900,color:#fff        ┌──────────────────────────────────────┐

```        │      Usuarios/Aplicaciones           │

        └──────────────────────────────────────┘

## 🛠️ Tecnologías```



| Componente | Tecnología | Versión |## 📁 Estructura del Proyecto

|------------|------------|---------|

| **Lenguaje** | Python | 3.11 |```

| **Framework** | FastAPI | 0.104.1 |cloud-m5/

| **Cliente Athena** | boto3 | 1.34+ |│

| **Formato Data Lake** | Apache Parquet | - |├── docker-compose.yml         # Orquestador maestro (usa 'include')

| **Orquestador** | AWS Glue | - |├── deploy-all.sh              # Script de despliegue para Ubuntu/Linux

| **Query Engine** | AWS Athena | - |├── .gitignore                 # Protege .env y archivos sensibles

| **Storage** | AWS S3 | - |│

| **Contenedor** | Docker | - |├── ms-databases/              # 3 bases de datos de prueba

│   ├── docker-compose.yml     # MySQL, PostgreSQL, MongoDB

## 🌐 API Endpoints│   ├── .env                   # Credenciales de BD (gitignored)

│   ├── .env.example           # Plantilla para configurar

### Analytics y Reportes│   ├── init-mysql.sql         # Datos de prueba MS1

│   ├── init-postgres.sql      # Datos de prueba MS2

| Método | Endpoint | Descripción |│   ├── init-mongo.js          # Datos de prueba MS3

|--------|----------|-------------|│   └── README.md              # Documentación detallada

| `GET` | `/dashboard-ejecutivo` | Dashboard con KPIs principales |│

| `GET` | `/cuentas/por-tipo` | Distribución de cuentas por tipo |├── datalake-ingester/         # ETL: Extrae y sube a S3

| `GET` | `/transacciones/por-mes` | Volumen de transacciones mensuales |│   ├── docker-compose.yml     # 3 ingesters (uno por DB)

| `GET` | `/clientes/activos` | Total de clientes activos |│   ├── ingester.py            # Lógica de ingesta (boto3)

| `GET` | `/ingresos/mensuales` | Ingresos por mantenimiento de cuentas |│   ├── .env                   # AWS credentials + S3 buckets

│   ├── .env.example           # Plantilla

### Consultas SQL Personalizadas│   ├── requirements.txt       # boto3, pymysql, psycopg2, pymongo

│   └── README.md              # Documentación ETL

| Método | Endpoint | Descripción |│

|--------|----------|-------------|└── api-consultas/             # API REST con FastAPI

| `POST` | `/query` | Ejecutar query SQL personalizada en Athena |    ├── docker-compose.yml     # Servicio API (puerto 8000)

| `GET` | `/query/{execution_id}` | Obtener resultado de query por ID |    ├── main.py                # Endpoints de FastAPI

    ├── athena_client.py       # Cliente para consultas Athena

### Utilidades    ├── queries.py             # Queries SQL predefinidas

    ├── .env                   # AWS credentials + config Athena

| Método | Endpoint | Descripción |    ├── .env.example           # Plantilla

|--------|----------|-------------|    ├── requirements.txt       # fastapi, boto3, uvicorn

| `GET` | `/` | Información del servicio |    ├── DataLake_API_Postman_Collection.json  # 16 requests

| `GET` | `/health` | Health check |    └── README.md              # Documentación API con endpoints

| `GET` | `/docs` | Documentación Swagger UI |```



## 📊 Modelo de Respuesta## � Arquitectura de Redes Docker



### Dashboard Ejecutivo### Conectividad Entre Componentes

```json

{```

  "fecha_generacion": "2025-01-15T10:30:00",┌─────────────────────────────────────────────────┐

  "total_clientes": 15234,│          Red: datalake-network                  │

  "clientes_activos": 14892,│          (Comunicación interna)                 │

  "total_cuentas": 28456,│                                                 │

  "saldo_total_sistema": 125000000.50,│  ┌──────────┐  ┌───────────┐  ┌──────────┐    │

  "transacciones_mes_actual": 45678,│  │ MySQL    │  │PostgreSQL │  │ MongoDB  │    │

  "ingresos_mantenimiento": 284560.00,│  │ :3306    │  │  :5432    │  │ :27017   │    │

  "distribucion_cuentas": {│  └──────────┘  └───────────┘  └──────────┘    │

    "Ahorro": 18234,│       ↑              ↑              ↑          │

    "Corriente": 8123,│       │   Conexión directa via    │          │

    "Plazo Fijo": 2099│       │   nombres de contenedores  │          │

  }│       └──────────────┴──────────────┘          │

}│                      │                         │

```│           ┌──────────────────────┐             │

│           │  Ingester Containers │             │

### Transacciones por Mes│           │  - ingesta01-mysql   │             │

```json│           │  - ingesta02-postgres│             │

{│           │  - ingesta03-mongodb │             │

  "periodo": "2024-01-01 a 2024-12-31",│           └──────────────────────┘             │

  "data": [│                                                 │

    {└─────────────────────────────────────────────────┘

      "mes": "2024-01",

      "total_transacciones": 3456,        ┌─────────────────┐

      "monto_total": 1250000.00        │  API-Consultas  │  ← NO necesita red Docker

    },        │    :8000        │     (solo se comunica con AWS)

    {        └─────────────────┘

      "mes": "2024-02",                │

      "total_transacciones": 3789,                ↓ HTTPS (boto3)

      "monto_total": 1380000.00        ┌─────────────────┐

    }        │  Amazon Athena  │

  ]        │  (AWS Cloud)    │

}        └─────────────────┘

```                │

                ↓ Query S3

## 📊 Estructura del Data Lake        ┌─────────────────┐

        │   Amazon S3     │

**S3 Bucket**: `s3://cloud-bank-datalake/`        └─────────────────┘

```

**Estructura de Directorios:**

```### ¿Quién necesita estar en la red Docker?

s3://cloud-bank-datalake/

├── clientes/| Componente | Red Docker | Razón |

│   ├── clientes.parquet|------------|------------|-------|

│   └── _metadata| **ms-databases** | ✅ `datalake-network` | Crea la red para que otros componentes se conecten |

├── cuentas/| **datalake-ingester** | ✅ `datalake-network` | Necesita conectarse directamente a las 3 bases de datos usando nombres de contenedores (`mysql-db`, `postgres-db`, `mongo-db`) |

│   ├── cuentas.parquet| **api-consultas** | ❌ **NO necesita red** | Solo se comunica con Amazon Athena (servicio AWS en la nube). No accede directamente a las bases de datos |

│   └── _metadata

└── transacciones/### Flujo de Conexiones

    ├── year=2024/

    │   ├── month=01/1. **Ingesters → Bases de Datos**: Conexión directa dentro de `datalake-network`

    │   │   └── transacciones.parquet   - Host: `mysql-db`, `postgres-db`, `mongo-db` (nombres de contenedores)

    │   ├── month=02/   - Comunicación: TCP interno de Docker

    │   │   └── transacciones.parquet

    └── _metadata2. **Ingesters → S3**: Conexión HTTPS vía boto3 SDK

```   - Usa IAM Role del EC2 para autenticación

   - No requiere credenciales hardcoded

**AWS Glue Tables:**

- `cloud_bank_db.clientes`3. **API → Athena/S3**: Conexión HTTPS vía boto3 SDK

- `cloud_bank_db.cuentas`   - Usa IAM Role del EC2 para autenticación

- `cloud_bank_db.transacciones`   - Lee datos desde S3 vía queries Athena

   - **Nunca accede directamente a las bases de datos**

## ☁️ Servicios AWS Utilizados

### Configuración de Red con `include`

- **EC2**: Hospedaje de la API

- **S3**: Almacenamiento del Data Lake (formato Parquet)Cuando se usa `include` en Docker Compose (como en este proyecto):

- **Athena**: Motor de consultas SQL sobre S3

- **Glue**: Catálogo de datos y crawler1. **El archivo raíz** (`docker-compose.yml`) define la red:

- **IAM**: Permisos para acceso a S3/Athena   ```yaml

- **VPC & Security Groups**: Red y firewall   networks:

     datalake-network:

## 🚀 Despliegue Rápido       driver: bridge

   ```

```bash

# En la instancia EC22. **Los archivos individuales** referencian la red pero **NO la definen**:

cd ~/cloud-bank-service/ms5/api-consultas   ```yaml

   services:

# Configurar AWS credentials y S3 bucket en .env     mysql-db:

# AWS_ACCESS_KEY_ID=AKIA...       networks:

# AWS_SECRET_ACCESS_KEY=...         - datalake-network

# AWS_REGION=us-east-1   

# S3_BUCKET=cloud-bank-datalake   # ❌ NO incluir sección "networks:" al final del archivo

   ```

docker-compose up -d

3. **La red se crea automáticamente** al ejecutar:

# Verificar   ```bash

curl http://localhost:8000/health   docker-compose up -d

curl http://localhost:8000/docs   ```

```

**Importante**: Los archivos `ms-databases/docker-compose.yml` y `datalake-ingester/docker-compose.yml` solo **referencian** la red en los servicios, pero no la definen al final. Esto evita conflictos con el `include`.

Ver guía completa: `../DEPLOYMENT_GUIDE.md`

## �🚀 Inicio Rápido en EC2 Ubuntu

## 🔗 Dependencias

### Pre-requisitos

**Consumido por:**

- Dashboards ejecutivos1. **EC2 Ubuntu 22.04** (t2.medium o superior recomendado)

- Herramientas de BI (Tableau, Power BI, etc.)2. **IAM Role** con permisos S3, Glue y Athena (ej: `LabRole` para AWS Academy)

- Reportes programados3. **3 Buckets S3** creados:

   - `raw-ms1-data-bgc` (para MySQL)

**Consume:**   - `raw-ms2-data-bgc` (para PostgreSQL)

- AWS S3 (Data Lake)   - `raw-ms3-data-bgc` (para MongoDB)

- AWS Athena (Query Engine)4. **Docker y Docker Compose instalados** en EC2

- Datos históricos de MS1, MS2, MS4 (a través del Data Lake)

### Instalación de Docker en Ubuntu

## 📖 Documentación Adicional

```bash

- **Swagger UI**: `http://{EC2-IP}:8000/docs`# Actualizar sistema

- **OpenAPI Spec**: `http://{EC2-IP}:8000/openapi.json`sudo apt update && sudo apt upgrade -y

- **Data Lake Setup**: Ver `check_s3_structure.sh`, `check_glue_tables.py`

- **Ingester**: Ver `../datalake-ingester/README.md`# Instalar Docker

- **Guía de deployment detallada**: Ver `../DEPLOYMENT_GUIDE.md`curl -fsSL https://get.docker.com -o get-docker.sh

sudo sh get-docker.sh

## 📝 Notas

# Agregar usuario al grupo docker (evita usar sudo)

- Las consultas en Athena escanean datos en S3, se cobra por TB escaneadosudo usermod -aG docker $USER

- El formato Parquet optimiza el escaneo (columnar, comprimido)newgrp docker

- Los datos se particionan por año/mes para eficiencia

- El Data Ingester corre periódicamente para actualizar el Data Lake# Verificar instalación

- Athena queries son asíncronas (se obtiene execution_id para consultar resultado)docker --version

- Se recomienda usar vistas materializadas para dashboards de actualización frecuentedocker compose version

```

### 1. Clonar el Proyecto y Configurar Variables

```bash
# Clonar repositorio
git clone <tu-repositorio-url>
cd cloud-m5

# Configurar variables de entorno en cada componente
cd ms-databases
cp .env.example .env
nano .env  # Editar credenciales

cd ../datalake-ingester
cp .env.example .env
nano .env  # Configurar AWS credentials y buckets S3

cd ../api-consultas
cp .env.example .env
nano .env  # Configurar AWS credentials y Athena

cd ..  # Volver a raíz
```

**⚠️ IMPORTANTE**: Los archivos `.env` contienen credenciales reales y NO se suben a Git.

### 2. Desplegar Todos los Servicios

#### Verificar versión de Docker Compose

```bash
# Docker Compose V2 (más reciente - integrado con Docker)
docker compose version

# Docker Compose V1 (versión antigua - comando separado)
docker-compose --version
```

**Nota**: Los comandos cambian según la versión:
- **V2**: `docker compose` (con espacio)
- **V1**: `docker-compose` (con guión)

En los ejemplos siguientes usaremos **V1** (`docker-compose`), si tienes V2 usa `docker compose`.

#### Opción A: Docker Compose desde la Raíz (Más Simple)

```bash
# Levanta TODOS los servicios (7 contenedores)
docker compose up -d

# Ver estado
docker compose ps

# Ver logs en tiempo real
docker compose logs -f

# Detener todo
docker compose down
```

#### Opción B: Script Bash con Comandos Útiles

```bash
# Dar permisos de ejecución
chmod +x deploy-all.sh

# Levantar todos los servicios (con espera de 15s para DBs)
./deploy-all.sh start

# Ver estado de todos los contenedores
./deploy-all.sh status

# Ver logs de todos los servicios
./deploy-all.sh logs

# Detener todos los servicios
./deploy-all.sh stop

# Reiniciar todos los servicios
./deploy-all.sh restart

# Reconstruir contenedores después de cambios
./deploy-all.sh rebuild
```

### 3. Configurar AWS Glue (Desde AWS Console)

```bash
# 1. Crear base de datos en Glue
aws glue create-database --database-input '{"Name": "datalake_db"}'

# 2. Crear y ejecutar 3 crawlers (uno por bucket S3)
# Configurar desde AWS Console:
#   - Crawler 1: raw-ms1-data-bgc → tabla: ms1_*
#   - Crawler 2: raw-ms2-data-bgc → tabla: ms2_*
#   - Crawler 3: raw-ms3-data-bgc → tabla: ms3_*

# 3. Ejecutar crawlers para catalogar datos
# Resultado esperado: 9 tablas en Glue Data Catalog
```

### 4. Verificar Despliegue

```bash
# Ver contenedores corriendo (deberías ver 7)
docker ps

# Probar bases de datos
docker logs mysql-test-db
docker logs postgres-test-db
docker logs mongo-test-db

# Probar ingesters (deben ejecutarse y terminar)
docker logs ingesta01-mysql
docker logs ingesta02-postgresql
docker logs ingesta03-mongodb

# Probar API REST
curl http://localhost:8000/health
# Respuesta esperada: {"status":"healthy"}

# Ver Swagger UI en navegador
# http://<IP-PUBLICA-EC2>:8000/docs
```

## � Servicios Desplegados

| Servicio | Puerto | Descripción |
|----------|--------|-------------|
| **mysql-test-db** | 3307 | MySQL 8.0 con datos de MS1 (usuarios, pedidos, productos) |
| **postgres-test-db** | 5433 | PostgreSQL 15 con datos de MS2 (clientes, facturas, pagos) |
| **mongo-test-db** | 27018 | MongoDB 7.0 con datos de MS3 (logs, sesiones, eventos) |
| **ingesta01-mysql** | - | Extrae MySQL → S3 (formato JSON Lines) |
| **ingesta02-postgresql** | - | Extrae PostgreSQL → S3 (formato JSON Lines) |
| **ingesta03-mongodb** | - | Extrae MongoDB → S3 (formato JSON Lines) |
| **api-consultas-datalake** | 8000 | API REST con 15+ endpoints (Athena queries) |

## 🌐 API REST - Endpoints Principales

Accede a la documentación interactiva: **`http://<EC2-IP>:8000/docs`**

### Endpoints Disponibles:

- `GET /health` - Health check
- `GET /api/dashboard` - Dashboard general con métricas
- `GET /api/usuarios` - Listar usuarios (MS1)
- `GET /api/pedidos` - Listar pedidos (MS1)
- `GET /api/productos` - Listar productos (MS1)
- `GET /api/clientes` - Listar clientes (MS2)
- `GET /api/facturas` - Listar facturas (MS2)
- `GET /api/pagos` - Listar pagos (MS2)
- `GET /api/logs` - Listar logs (MS3)
- `GET /api/sesiones` - Listar sesiones (MS3)
- `GET /api/eventos` - Listar eventos (MS3)
- `GET /api/pedidos/{pedido_id}` - Pedido por ID
- `GET /api/productos-por-categoria/{categoria}` - Productos filtrados
- `GET /api/facturas-por-cliente/{cliente_id}` - Facturas de cliente
- `POST /api/query-custom` - Ejecutar query SQL personalizada

**📥 Importar Postman Collection**: `api-consultas/DataLake_API_Postman_Collection.json` (16 requests listos)

## 📚 Documentación Detallada por Componente

- **[ms-databases/README.md](./ms-databases/README.md)** - Bases de datos, esquemas, datos de prueba
- **[datalake-ingester/README.md](./datalake-ingester/README.md)** - Ingesters, formato JSON Lines, particiones S3
- **[api-consultas/README.md](./api-consultas/README.md)** - API REST, endpoints, Athena queries, ejemplos

## 🛠️ Tecnologías Utilizadas

| Categoría | Tecnología | Versión |
|-----------|------------|---------|
| **Cloud** | AWS S3, Glue, Athena, EC2, IAM | - |
| **Lenguaje** | Python | 3.11 |
| **Framework API** | FastAPI | 0.104.1 |
| **SDK AWS** | boto3 | 1.34.0 |
| **Bases de Datos** | MySQL | 8.0 |
| | PostgreSQL | 15 |
| | MongoDB | 7.0 |
| **Containerización** | Docker | 24.x |
| | Docker Compose | v3.8 |
| **Formato de Datos** | JSON Lines (NDJSON) | - |

## 🔐 Seguridad y Buenas Prácticas

### Archivos Protegidos (`.gitignore`):
- ✅ `.env` - Credenciales reales
- ✅ `*.pem`, `*.ppk` - Llaves SSH
- ✅ `notes.txt` - Notas personales
- ✅ `mysql-data/`, `postgres-data/`, `mongo-data/` - Volúmenes de datos

### Credenciales AWS:
- Usa **IAM Roles** en EC2 (no hardcodear access keys)
- Para AWS Academy usa `LabRole` / `LabInstanceProfile`
- Rota credenciales regularmente

## � Publicar Imágenes en Docker Hub (Opcional)

El proyecto incluye nombres de imágenes configurados para facilitar la publicación en Docker Hub.

### Imágenes del Proyecto

| Imagen | Tag | Descripción |
|--------|-----|-------------|
| `br4yangc/cloud-computing-project-ms-5` | `ingester-mysql` | Ingester para MySQL → S3 |
| `br4yangc/cloud-computing-project-ms-5` | `ingester-postgresql` | Ingester para PostgreSQL → S3 |
| `br4yangc/cloud-computing-project-ms-5` | `ingester-mongodb` | Ingester para MongoDB → S3 |
| `br4yangc/cloud-computing-project-ms-5` | `api-consultas` | API REST con FastAPI para Athena |

**Nota**: Las bases de datos (MySQL, PostgreSQL, MongoDB) usan imágenes oficiales públicas y no requieren publicación.

### Proceso de Publicación

```bash
# 1. Login en Docker Hub (requiere cuenta gratuita en hub.docker.com)
docker login -u br4yangc

# 2. Construir todas las imágenes (desde la raíz del proyecto)
docker-compose build

# 3. Publicar imágenes en Docker Hub
docker push br4yangc/cloud-computing-project-ms-5:ingester-mysql
docker push br4yangc/cloud-computing-project-ms-5:ingester-postgresql
docker push br4yangc/cloud-computing-project-ms-5:ingester-mongodb
docker push br4yangc/cloud-computing-project-ms-5:api-consultas

# 4. Verificar en Docker Hub
# https://hub.docker.com/r/br4yangc/cloud-computing-project-ms-5/tags
```

### Ventajas de Publicar

- ✅ **Despliegue rápido**: Descarga imágenes pre-construidas en lugar de construir
- ✅ **Portabilidad**: Deploy en múltiples servidores sin clonar código fuente
- ✅ **Portafolio**: Proyecto visible públicamente y fácil de demostrar
- ✅ **Versionamiento**: Control de versiones con tags (`v1.0`, `v2.0`, etc.)
- ✅ **Colaboración**: Otros pueden probar tu proyecto fácilmente

### Usar Imágenes Publicadas

Una vez publicadas, otros pueden desplegar sin construir:

```bash
# Clonar solo archivos de configuración
git clone <tu-repo-url>
cd cloud-computing-project-ms-5

# Configurar .env en cada carpeta

# Descargar imágenes pre-construidas
docker-compose pull

# Levantar servicios (sin necesidad de construir)
docker-compose up -d
```

### Límites del Plan Gratuito

Docker Hub plan gratuito incluye:
- ✅ Repositorios públicos ilimitados
- ✅ 1 repositorio privado
- ✅ Sin límite de pulls autenticados
- ⚠️ 200 pulls cada 6 horas para usuarios anónimos

## �🔧 Comandos Útiles

```bash
# Ver logs de un servicio específico
docker logs -f <nombre-contenedor>

# Reiniciar un servicio
docker compose restart <nombre-servicio>

# Reconstruir después de cambios en código
docker compose up -d --build

# Detener y eliminar volúmenes (⚠️ elimina datos de BD)
docker compose down -v

# Ver uso de recursos
docker stats

# Limpiar contenedores detenidos
docker system prune -a

# Ver redes Docker
docker network ls

# Inspeccionar un contenedor
docker inspect <nombre-contenedor>
```

## 🐛 Troubleshooting

### Error: "networks.datalake-network conflicts with imported resource"

Este error ocurre cuando múltiples archivos docker-compose intentan definir la misma red.

**Solución**: La red debe definirse **solo en el archivo raíz** (`docker-compose.yml`):

```yaml
# docker-compose.yml (raíz)
networks:
  datalake-network:
    driver: bridge
```

Los archivos individuales (`ms-databases/`, `datalake-ingester/`) **NO** deben tener sección `networks:` al final, solo referencian la red en los servicios.

```bash
# Si persiste el error, limpiar y reiniciar:
docker-compose down
docker network prune -f
docker-compose up -d
```

**Nota importante**: Solo los **ingesters** y **bases de datos** necesitan estar en la red `datalake-network`. La **API** no necesita esta red porque solo se comunica con Athena (AWS).

### Error: "Cannot connect to Docker daemon"
```bash
# Verificar que Docker esté corriendo
sudo systemctl status docker

# Iniciar Docker
sudo systemctl start docker

# Agregar usuario al grupo docker
sudo usermod -aG docker $USER
newgrp docker
```

### Error: "The container name is already in use"

Este error ocurre cuando hay contenedores de intentos anteriores que no se eliminaron.

```bash
# Detener todos los servicios
docker-compose down

# Eliminar contenedores específicos que quedaron
docker rm -f $(docker ps -aq --filter "name=ingesta") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=mysql-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=postgres-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=mongo-test") 2>/dev/null || true
docker rm -f $(docker ps -aq --filter "name=api-consultas") 2>/dev/null || true

# Limpiar redes huérfanas
docker network prune -f

# Levantar servicios limpios
docker-compose up -d
```

### Error: "Port already in use"
```bash
# Ver qué proceso usa el puerto
sudo lsof -i :8000

# O cambiar puerto en .env del servicio
```

### Error: "Permission denied" en S3
- Verifica que el IAM Role en EC2 tenga políticas: `AmazonS3FullAccess`, `AWSGlueConsoleFullAccess`, `AmazonAthenaFullAccess`
- Revisa que los buckets existan en la región correcta (us-east-1)
- Verifica credenciales en archivos `.env`

### Athena devuelve errores de tipos de datos
- Verifica que los datos en S3 estén en **JSON Lines** (no JSON pretty-printed)
- Ejecuta los Glue Crawlers para actualizar el esquema
- Los ingesters ya convierten `Decimal` → `float` y `datetime` → `ISO string`

### Ingesters no suben datos a S3
```bash
# Ver logs de ingesters
docker logs ingesta01-mysql
docker logs ingesta02-postgresql
docker logs ingesta03-mongodb

# Verificar conectividad con AWS
aws s3 ls s3://raw-ms1-data-bgc/

# Revisar .env en datalake-ingester/
```

### Warnings: "AWS_ACCESS_KEY_ID variable is not set"
Estos warnings son **normales y esperados** si usas IAM Role en EC2:
```
WARN[0000] The "AWS_ACCESS_KEY_ID" variable is not set. Defaulting to a blank string.
WARN[0000] The "AWS_SECRET_ACCESS_KEY" variable is not set. Defaulting to a blank string.
WARN[0000] The "AWS_SESSION_TOKEN" variable is not set. Defaulting to a blank string.
```

**Puedes ignorarlos** porque:
- El EC2 usa IAM Role (`LabRole`) para autenticación automática
- No necesitas credenciales hardcoded en los `.env`
- Los servicios obtienen credenciales temporales del EC2 metadata service

Si prefieres eliminar los warnings, deja las variables vacías en los `.env`:
```bash
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=
AWS_SESSION_TOKEN=
```

### API devuelve 500 Internal Server Error
```bash
# Ver logs de la API
docker logs api-consultas-datalake

# Verificar que Glue Data Catalog tenga tablas
aws glue get-tables --database-name datalake_db

# Verificar .env en api-consultas/
```

## 📝 Limitaciones de AWS Academy

- ⚠️ **No puedes crear IAM Roles nuevos** → Usa `LabRole` existente
- ⚠️ **Sesiones expiran después de 4 horas** → Re-inicia la lab
- ⚠️ **Algunos servicios están restringidos** (Lambda, RDS managed, etc.)
- ✅ **S3, Glue, Athena y EC2 funcionan perfectamente**

## 🤝 Contribución

```bash
# 1. Copiar plantillas de variables
cp ms-databases/.env.example ms-databases/.env
cp datalake-ingester/.env.example datalake-ingester/.env
cp api-consultas/.env.example api-consultas/.env

# 2. Configurar credenciales reales (NO subir a Git)

# 3. Hacer cambios en código

# 4. Probar localmente
docker compose up -d --build

# 5. Asegurarse que .env esté en .gitignore

# 6. Commit y push (sin .env)
git add .
git commit -m "descripción"
git push
```

## 📄 Licencia

Proyecto educativo para AWS Academy - Cloud Computing.

---

**Desarrollado con ☁️ para aprender arquitecturas DataLake en AWS**
